<!DOCTYPE html><html lang="en-us"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>One-Page Overview - CINPCT 2025</title><meta name="description" content="Problem Statement People with Profound Intellectual and Multiple Disabilities (PIMD) face significant challenges in expressing emotions and communicating ideas due&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="./../one-page-overview/"><link rel="preload" href="./../assets/dynamic/fonts/labrada/labrada.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="./../assets/dynamic/fonts/labrada/labrada-italic.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="./../assets/dynamic/fonts/domine/domine.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="./../assets/css/style.css?v=d07737cfd40235675cd56d0787913355"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"./../one-page-overview/"},"headline":"One-Page Overview","datePublished":"2025-04-02T14:30-04:00","dateModified":"2025-04-04T13:30-04:00","description":"Problem Statement People with Profound Intellectual and Multiple Disabilities (PIMD) face significant challenges in expressing emotions and communicating ideas due&hellip;","author":{"@type":"Person","name":"Project Voice @ RPI","url":"./../authors/project-voice-rpi/"},"publisher":{"@type":"Organization","name":"Project Voice @ RPI"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="page-template lines"><div class="container lines lines--right"><header class="header"><a href="./../" class="logo">CINPCT 2025</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu">Menu</button><ul class="navbar__menu"><li><a href="./../" target="_self">Home</a></li><li><a href="./../cinpct/conference-organizers/" target="_self">Conference Organizers</a></li><li class="active-parent has-submenu"><span class="is-separator" aria-haspopup="true">Program Overview</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="./../cinpct/agenda/" target="_self">Agenda</a></li><li class="active"><a href="./../one-page-overview/" target="_self">One-Page Overview</a></li></ul></li><li class="has-submenu"><span class="is-separator" aria-haspopup="true">Organization</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="./../cinpct/conference-organizers/" target="_self">Conference Organizers</a></li><li><a href="./../cinpct/sponsors/" target="_self">Sponsors</a></li></ul></li><li><a href="https://www.gofundme.com/" target="_blank">Support Us</a></li></ul></nav></header><main class="main page"><article class="content"><header class="content__inner content__header"><h1 class="content__title">One-Page Overview</h1></header><div class="content__inner"><div class="content__entry"><p><strong>Problem Statement</strong></p><p><span style="font-weight: 400;">People with Profound Intellectual and Multiple Disabilities (PIMD) face significant challenges in expressing emotions and communicating ideas due to severe cognitive and physical impairments (Nakken &amp; Vlaskamp, 2007). Current assistive technology for non-verbal individuals rely primarily on symbolic-based communication (selecting pictures, or using sign language) or require fine-tuned motor skills to type (letter boards, Trinh’s PhonicStick). Those assistive devices may be helpful for people with lower levels of intellectual disabilities, but they may not be accessible to people with PIMD due to their limited ability to manipulate external devices (Bruce &amp; Bashinski, 2017).</span></p><p> </p><p><span style="font-weight: 400;">This project aims to create a home-use alternative assistive communication device that can be used specifically by individuals with PIMD. The proposed system will focus on utilizing unaided forms of communication, including information such body language, vocalizations, and biological signals to infer cognitive intent.</span></p><p> </p><p><strong>Literature Review</strong></p><p><span style="font-weight: 400;">We plan on building on top of previous research that has been done with both patients with PIMD and people without intellectual disabilities building correlations between biological signals, vocalizations, and gestural data and their emotional state and cognitive intent. In previous instances, researchers have been successfully able to classify different gestures of people with PIMD using Machine Learning by contextualizing it with environmental data using just a mobile app (Herbuela, 2022). Another study has also used a similar method to recognize vocalizations made by individuals with PIMD with the goal of determining their emotional state (Jęśko, 2021). EEG signals and heart rate variability are indicators that are not heavily influenced by individual arbitrariness, and have been proven to provide estimates of a person’s emotional state (Miyagi, 2024). We plan on using a similar method for our own research project, and test whether a system measuring heart rate variability, blood pressure, and vocalizations can give insight into the emotional state of a person with PIMD.</span></p><p> </p><p><strong>Impact</strong></p><p><span style="font-weight: 400;">If successful, this project can be one step forward in providing a more meaningful method of non-verbal communication. Due to communication barriers, people with PIMD are reported to experience severe social isolation, which can in turn lead to deteriorating mental and physical health (Schuengel et al., 2022). Because of this, giving them a way to expressively communicate with their peers could lead to a significant improvement in their overall well-being. It will also alleviate the reliance on caregivers for basic interactions and provide more autonomy to individuals with PIMD in everyday life.</span></p><p> </p><p><strong>References</strong></p><p><span style="font-weight: 400;">Miyagi, Y. , Gocho, S. , Miyachi, Y. , Nakayama, C. , Okada, S. , Maruyama, K. and Oshima, T. (2024) Emotion Measurement Using Biometric Signal. Health, 16, 395-404. doi: 10.4236/health.2024.165028.</span></p><p> </p><p><span style="font-weight: 400;">Bradshaw, J., Maguire, R., Gillooly, A., Hatton, C., Caton, S., Jahoda, A., Oloidi, E., Taggart, L., Todd, S. and Hastings, R. (2024), What Would Have Helped People With Profound Intellectual and Multiple Disabilities in the UK During COVID-19?. J Policy Pract Intellect Disabil, 21: e70000. https://doi.org/10.1111/jppi.70000</span></p><p> </p><p><span style="font-weight: 400;">Nakken, H. and Vlaskamp, C. (2007), A Need for a Taxonomy for Profound Intellectual and Multiple Disabilities. Journal of Policy and Practice in Intellectual Disabilities, 4: 83-87. https://doi.org/10.1111/j.1741-1130.2007.00104.x</span></p><p> </p><p><span style="font-weight: 400;">Herbuela, V. R. D. M., Karita, T., Furukawa, Y., Wada, Y., Toya, A., Senba, S., Onishi, E., &amp; Saeki, T. (2022). Machine learning-based classification of the movements of children with profound or severe intellectual or multiple disabilities using environment data features. PloS one, 17(6), e0269472. </span><a href="https://doi.org/10.1371/journal.pone.0269472"><span style="font-weight: 400;">https://doi.org/10.1371/journal.pone.026947</span></a><span style="font-weight: 400;">2</span></p><p> </p><p><span style="font-weight: 400;">Jęśko, W. (2021). Vocalization recognition of people with profound intellectual and multiple disabilities (PIMD) using machine learning algorithms. Proceedings of Interspeech 2021, 2921–2925. </span><a href="https://doi.org/10.21437/Interspeech.2021-1239"><span style="font-weight: 400;">https://doi.org/10.21437/Interspeech.2021-1239</span></a></p><p> </p><p><span style="font-weight: 400;">Bruce SM, Bashinski SM. The Trifocus Framework and Interprofessional Collaborative Practice in Severe Disabilities. Am J Speech Lang Pathol. 2017 May 17;26(2):162-180. doi: 10.1044/2016_AJSLP-15-0063. PMID: 28514472.</span></p><p> </p></div></div></article></main><footer class="footer"><div class="footer__left"><div class="footer__copy">2025 © Project Voice RPI</div></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="./../assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = { mobileMenuMode: 'sidebar', animationSpeed: 300, submenuWidth: 'auto', doubleClickTime: 500, mobileMenuExpandableSubmenus: true, relatedContainerForOverlayMenuSelector: '.navbar', };</script><script defer="defer" src="./../assets/js/scripts.min.js?v=9c5ab7a87221183f149a42b3cceb7956"></script><script>function publiiDetectLoadedImages () {
         var images = document.querySelectorAll('img[loading]:not(.is-loaded)');
         for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
               images[i].classList.add('is-loaded');
               images[i].parentNode.classList.remove('is-img-loading');
            } else {
               images[i].addEventListener('load', function () {
                  this.classList.add('is-loaded');
                  this.parentNode.classList.remove('is-img-loading');
               }, false);
            }
         }
      }
      publiiDetectLoadedImages();</script></body></html>